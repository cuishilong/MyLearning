## 数据仓库

基于Hive,Hbase的数仓建设

### 数据源

1、实体数据

抽象实体，比如用户表，商品表

一般存储在数据库中

2、业务数据

实体产生的业务，比如订单表，收藏表

一般存储在OLTP库中

3、行为数据

实体的行为，比如日志，页面日志，浏览日志等

存储在文件或数据库中

4、媒体数据

商品，音频，图片等



### 一、数据接入


#### 接入方式

Flume

Kettle

Api

Kafka

Sqoop

ELK


#### 接入策略

全量

增量

实时

批量


### 二、数据仓库

数据分层

ODS：DIM，接入表，DIC

CDM：DWD，DWS（）

ADS：面向业务，业务宽表，指标表

事实表设计（事实粒度，作为度量，null值处理，单一事实粒度下的唯一性，事实表中维度的退化）

维表设计（缓慢变化维/缓慢增长维，层级维度，通用维度沉淀，事实和维度相关字段边界确定，维度粒度）

拉链表（非分区桶表）

```hiveql
create external table if not exists tmp.tmp_zipper
(
    remote_addr            String COMMENT "客户端地址",
    remote_user            String COMMENT "客户端用户名称",
    time_local             String COMMENT "访问时间和时区",
    request_type           String COMMENT "请求方式",
    request_uri            String COMMENT "请求资源uri",
    request_protocol       String COMMENT "请求协议",
    http_host              String COMMENT "请求地址，即浏览器中你输入的地址（IP或域名）",
    status                 String COMMENT "HTTP请求状态",
    upstream_status        String COMMENT "upstream状态",
    body_bytes_sent        String COMMENT "发送给客户端文件内容大小",
    http_referer           String COMMENT "url跳转来源",
    http_user_agent        String COMMENT "用户终端浏览器等信息",
    ssl_protocol           String COMMENT "SSL协议版本",
    ssl_cipher             String COMMENT "交换数据中的算法",
    upstream_addr          String COMMENT "台upstream的地址，即真正提供服务的主机地址",
    request_time           String COMMENT "整个请求的总时间",
    upstream_response_time String COMMENT "请求过程中，upstream响应时间",
    server_addr            String COMMENT "服务器ip",
    request_length         String COMMENT "客户端发送给服务器数据大小"
)COMMENT "Nginx日志解析表" clustered by(sno) into 3 buckets stored as ParquetFile ;

```


### 三、数据服务

面向分析型仓库

面向存储型仓库


